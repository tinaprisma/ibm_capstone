{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# Choosing a U.S. City to Live In To Pursue Data Science Career", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "## Introduction ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Pursuing a Data Science career is an exciting career option for scientists and business people wanting to break into the technology industry.\n\nOne common consideration when transitioning into a tech career is whether or not it would be beneficial to move into a tech hub such as San Francisco. \n\nAlthough San Francisco is an attractive option, there are other considerations that should be weighed in order to make the best decision.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## Objective", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "To evaluate several U.S. cities based on cultural and climatological data to determine which cities would be a good fit to personal preferences.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## Preferences", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "- Weather: A mild weather is preferred.\n- Scenery: A city near mountains is preferred.\n- Urbanization and beautification: A city with a large number of parks is preferred.\n- Outdoors: the availability of hiking trails and outdoor venues is preferred.\n- Career: tech hub.\n- Pollen and mold: Lower pollen and mold counts are preferred.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## Audience", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "This project may be of interest to any person trying to figure out where to move. \nIn order to make an objective, responsible decision, one must research and weigh pros and cons.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## Data", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Data will be downloaded and scraped from various sources including Foursquare and U.S. government sites.\nThe Foursquare data will be used to determine how many venues fit in my personal interests per city.\nThe climatological data will be used to record high and low temperature extremes for each city as well as yearly precipitation volume.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## Methodology", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "First, import libraries needed for this analysis.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### 1. Import Libraries", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "import pandas as pd\nimport numpy as np\nimport requests\n\nimport numpy as np # library to handle data in a vectorized manner\nimport json # library to handle JSON files\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm # Matplotlib and associated plotting modules\nimport matplotlib.colors as colors\n\nimport plotly\nimport plotly.plotly as py\nimport plotly.figure_factory as ff\nimport plotly.graph_objs as go\nfrom plotly import tools\n\n\n!conda install -c conda-forge geopy --yes # uncomment this line if you haven't completed the Foursquare API lab\nfrom geopy import Nominatim # convert an address into latitude and longitude values\nfrom pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\nfrom pandas.io.html import read_html\nfrom sklearn.cluster import KMeans # import k-means from clustering stage\n\n!conda install -c conda-forge folium=0.5.0 --yes # uncomment this line if you haven't completed the Foursquare API lab\nimport folium # map rendering library\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\nprint('Libraries imported.')", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Fetching package metadata .............\nSolving package specifications: .\n\nPackage plan for installation in environment /opt/conda/envs/DSX-Python35:\n\nThe following NEW packages will be INSTALLED:\n\n    geographiclib: 1.49-py_0   conda-forge\n    geopy:         1.19.0-py_0 conda-forge\n\ngeographiclib- 100% |################################| Time: 0:00:00  12.85 MB/s\ngeopy-1.19.0-p 100% |################################| Time: 0:00:00  17.86 MB/s\nFetching package metadata .............\nSolving package specifications: .\n\nPackage plan for installation in environment /opt/conda/envs/DSX-Python35:\n\nThe following NEW packages will be INSTALLED:\n\n    altair:  2.2.2-py35_1 conda-forge\n    branca:  0.3.1-py_0   conda-forge\n    folium:  0.5.0-py_0   conda-forge\n    vincent: 0.4.4-py_1   conda-forge\n\naltair-2.2.2-p 100% |################################| Time: 0:00:00  37.69 MB/s\nbranca-0.3.1-p 100% |################################| Time: 0:00:00  28.91 MB/s\nvincent-0.4.4- 100% |################################| Time: 0:00:00  20.12 MB/s\nfolium-0.5.0-p 100% |################################| Time: 0:00:00  23.40 MB/s\nLibraries imported.\n"
                }
            ], 
            "execution_count": 1
        }, 
        {
            "source": "### 2. Create a list with cities of interest", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# Enter the names of the cities of interest for this analysis\ncities = ['Houston, TX','Austin, TX','Dallas, TX','San Antonio, TX','Fort Worth, Texas','San Francisco, CA','San Jose, CA','Santa Rosa, CA','Palo Alto, CA','Los Angeles, CA','Santa Barbara, CA',\n          'San Diego, CA','Long Beach, CA','Palmdale, CA','Bakersfield, CA','Fresno, CA','Seattle, WA','Portland,OR','Miami, FL','Orlando, FL','Atlanta, GA','New Orleans, LA','Grand Junction, CO',\n          'Denver, CO','Colorado Springs, CO','New York, NY', 'Arlington, VA','Anchorage, AK','Sacramento, CA','Tampa, FL','Des Moines, IA','Reno, NV','Las Vegas, NV',\n          'Chicago, IL','Detroit, MI','Boston, MA','New Haven, CT', 'St. Louis, MO','Phoenix, AR','Albuquerque, NM','Oklahoma City, OK']\n\nlen(cities)\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "41"
                    }, 
                    "execution_count": 2
                }
            ], 
            "execution_count": 2
        }, 
        {
            "source": "### 3.  Explore Foursquare Data", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Browse Foursquare.com and find venue categories of interest.\nRecord Category IDs and order them in thematical lists.\n\nIn this analysis, venue data is extracted to determine whether one city or another has more venues of interest.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "#Outdoors and Recreation Venues: Trails, Bike Trail, Botanical Gardens, Forest, Mountain, Nature Preserve, National Park\n\noutdoors_venues_ID = ['4bf58dd8d48988d159941735','56aa371be4b08b9a8d57355e','52e81612bcbc57f1066b7a22','52e81612bcbc57f1066b7a23','4eb1d4d54b900d56c88a45fc','52e81612bcbc57f1066b7a13','52e81612bcbc57f1066b7a21']\n                      \n# Professional & Other Places:  Tech Startup, Convention Center, Observatory\n\nprofessional_venues_ID = ['4bf58dd8d48988d125941735','4bf58dd8d48988d1ff931735','5744ccdfe4b0c0459246b4d9']\n    \n#cultural venues:  Spiritual Center: Buddhist Temple, Hindu Temple, Synagoge, Winery\n\ncultural_venues_ID = ['52e81612bcbc57f1066b7a3e','52e81612bcbc57f1066b7a3f','4bf58dd8d48988d139941735','4bf58dd8d48988d14b941735']\n\n# Food and drink shop: Farmers Market, Health Food Store, Organic Grocery, Fruit and Vegetable Store, Juice Bar\n\nfood_venues_ID = ['4bf58dd8d48988d1fa941735','50aa9e744b90af0d42d5de0e','52f2ab2ebcbc57f1066b8b45','52f2ab2ebcbc57f1066b8b1c','4bf58dd8d48988d112941735']\n\n# Beautification: Park, Flower Shop, Art Studio\n\nbeauty_venues_ID = ['4bf58dd8d48988d163941735','4bf58dd8d48988d11b951735','58daa1558bbb0b01f18ec1d6']\n\ncategoryIDs = [outdoors_venues_ID,professional_venues_ID,cultural_venues_ID,food_venues_ID,beauty_venues_ID]\n\nprint('CategoryID list created.')\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "CategoryID list created.\n"
                }
            ], 
            "execution_count": 3
        }, 
        {
            "source": "### 4. Create a Function to Connect and Extract Data from Foursquare", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# This function connects to Foursquare and extracts venues matching a CategoryID and \n# stores them in the dataframe designated.\n\ndef getFoursquareCityData(cities, categoryIDs, limit, max_radius):\n\n    # Connect to Foursquare and Query each city to find the number of each venue.\n\n    client_ID = ''\n    client_secret = ''\n    version = '20180605' # Foursquare API version\n\n    print('Your credentails:')\n    print('CLIENT_ID: ' + client_ID)\n    print('CLIENT_SECRET:' + client_secret)\n\n    venues_list = []\n    venues_df = pd.DataFrame(columns = ['City','CategoryID','Venue','Latitude','Longitude','Type'])\n    \n    for city in cities:\n        for list in categoryIDs:\n            for category in list:\n                url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&near={}&radius={}&limit={}&categoryId={}'.format(\n                    client_ID,\n                    client_secret,\n                    version,\n                    city,\n                    max_radius,\n                    limit,\n                    category)\n\n                city_abr = city.upper()[:3]\n                try:\n                    venues = requests.get(url).json()['response']['groups'][0]['items']\n\n                    venues_list.append([(\n                    city,\n                    category,\n                    v['venue']['name'], \n                    v['venue']['location']['lat'], \n                    v['venue']['location']['lng'],\n                    v['venue']['categories'][0]['name']) for v in venues])\n                except IndexError:\n                    continue\n                except KeyError:\n                    continue\n\n            venues_df = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n        print(city_abr + \" records extracted.\")\n    print(\"The size of your venue dataframe is:\")\n    print(venues_df.shape)\n    return venues_df", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 4
        }, 
        {
            "source": "#### 5. Populate the venues dataframe with the raw data", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# Find venues near each city center around a 50 km radius (around 30 miles). Limit each venue list to 100 distinct venues\nvenues_df = getFoursquareCityData(cities, categoryIDs, 100, 100000)", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Your credentails:\nCLIENT_ID: \nCLIENT_SECRET:\nHOU records extracted.\nAUS records extracted.\nDAL records extracted.\nSAN records extracted.\nFOR records extracted.\nSAN records extracted.\nSAN records extracted.\nSAN records extracted.\nPAL records extracted.\nLOS records extracted.\nSAN records extracted.\nSAN records extracted.\nLON records extracted.\nPAL records extracted.\nBAK records extracted.\nFRE records extracted.\nSEA records extracted.\nPOR records extracted.\nMIA records extracted.\nORL records extracted.\nATL records extracted.\nNEW records extracted.\nGRA records extracted.\nDEN records extracted.\nCOL records extracted.\nNEW records extracted.\nARL records extracted.\nANC records extracted.\nSAC records extracted.\nTAM records extracted.\nDES records extracted.\nREN records extracted.\nLAS records extracted.\nCHI records extracted.\nDET records extracted.\nBOS records extracted.\nNEW records extracted.\nST. records extracted.\nPHO records extracted.\nALB records extracted.\nOKL records extracted.\nThe size of your venue dataframe is:\n(41967, 6)\n"
                }
            ], 
            "execution_count": 5
        }, 
        {
            "source": "venues_df.columns = ['City','CategoryID','Venue','Latitude','Longitude','Type']", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 6
        }, 
        {
            "source": "### 6. QC and Filter the Foursquare data in the dataframe", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "#### Data QC", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "venues_df.head()", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "          City                CategoryID                              Venue  \\\n0  Houston, TX  4bf58dd8d48988d159941735                 Buffalo Bayou Walk   \n1  Houston, TX  4bf58dd8d48988d159941735                 Buffalo Bayou Park   \n2  Houston, TX  4bf58dd8d48988d159941735  Houston Arboretum & Nature Center   \n3  Houston, TX  4bf58dd8d48988d159941735                 Herman Park Trails   \n4  Houston, TX  4bf58dd8d48988d159941735                 Terry Hershey Park   \n\n    Latitude  Longitude              Type  \n0  29.762177 -95.375844             Trail  \n1  29.762068 -95.391626              Park  \n2  29.765361 -95.452177  Botanical Garden  \n3  29.719804 -95.388748             Trail  \n4  29.779138 -95.623096              Park  ", 
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>City</th>\n      <th>CategoryID</th>\n      <th>Venue</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>Type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Houston, TX</td>\n      <td>4bf58dd8d48988d159941735</td>\n      <td>Buffalo Bayou Walk</td>\n      <td>29.762177</td>\n      <td>-95.375844</td>\n      <td>Trail</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Houston, TX</td>\n      <td>4bf58dd8d48988d159941735</td>\n      <td>Buffalo Bayou Park</td>\n      <td>29.762068</td>\n      <td>-95.391626</td>\n      <td>Park</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Houston, TX</td>\n      <td>4bf58dd8d48988d159941735</td>\n      <td>Houston Arboretum &amp; Nature Center</td>\n      <td>29.765361</td>\n      <td>-95.452177</td>\n      <td>Botanical Garden</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Houston, TX</td>\n      <td>4bf58dd8d48988d159941735</td>\n      <td>Herman Park Trails</td>\n      <td>29.719804</td>\n      <td>-95.388748</td>\n      <td>Trail</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Houston, TX</td>\n      <td>4bf58dd8d48988d159941735</td>\n      <td>Terry Hershey Park</td>\n      <td>29.779138</td>\n      <td>-95.623096</td>\n      <td>Park</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    }, 
                    "execution_count": 63
                }
            ], 
            "execution_count": 63
        }, 
        {
            "source": "First observations: \n- Found out Tree in Foursquare corresponds to tree cutting services - deleted it from categories for final report\n- Found out duplicates are present\n- Apparently there is a Hogwarts campus in Austin???\n- University, Library, Coworking Space as parameters are not as useful as initially we though. Deleted from categories.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "#Drop Duplicates!\nvenues_df = venues_df.drop_duplicates()\nprint('This is the size of the dataframe after dropping duplicates')\nvenues_df.shape", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "This is the size of the dataframe after dropping duplicates\n"
                }, 
                {
                    "output_type": "execute_result", 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "(41964, 6)"
                    }, 
                    "execution_count": 8
                }
            ], 
            "execution_count": 8
        }, 
        {
            "source": "Deleted ___ duplicate records!", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "#### Filtering the Data", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Let's find out which city has the most venues of interest and which one the least.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# This block of code creates a new dataframe that counts how many total venues are found per city\nvenues_count = pd.DataFrame(venues_df.groupby('City').count()['Venue'])\nvenues_count = venues_count.sort_values(by=['Venue'])\nvenues_count = venues_count.reset_index()\nmax_number = venues_count['Venue'].max()\nmax_city = venues_count.iloc[venues_count['Venue'].idxmax()][0]\nmin_number = venues_count['Venue'].min()\nmin_city = venues_count.iloc[venues_count['Venue'].idxmin()][0]\ncities = list(venues_count['City'])\nvenues_count", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "                    City  Venue\n0          Anchorage, AK    267\n1     Grand Junction, CO    277\n2            Phoenix, AR    422\n3        Bakersfield, CA    471\n4        Albuquerque, NM    481\n5               Reno, NV    484\n6      Oklahoma City, OK    492\n7             Fresno, CA    498\n8         Des Moines, IA    527\n9        New Orleans, LA    719\n10         St. Louis, MO    763\n11       San Antonio, TX    833\n12         Las Vegas, NV    840\n13           Portland,OR    930\n14     Santa Barbara, CA    938\n15           Houston, TX    950\n16  Colorado Springs, CO    984\n17           Detroit, MI    990\n18            Austin, TX   1007\n19     Fort Worth, Texas   1027\n20             Miami, FL   1034\n21            Dallas, TX   1036\n22           Orlando, FL   1067\n23             Tampa, FL   1092\n24         San Diego, CA   1095\n25           Atlanta, GA   1126\n26        Sacramento, CA   1169\n27            Denver, CO   1170\n28           Seattle, WA   1220\n29            Boston, MA   1313\n30         Arlington, VA   1338\n31           Chicago, IL   1342\n32        Santa Rosa, CA   1428\n33        Long Beach, CA   1533\n34       Los Angeles, CA   1537\n35          Palmdale, CA   1542\n36     San Francisco, CA   1547\n37          San Jose, CA   1549\n38         Palo Alto, CA   1567\n39         New Haven, CT   1597\n40          New York, NY   1762", 
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>City</th>\n      <th>Venue</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Anchorage, AK</td>\n      <td>267</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Grand Junction, CO</td>\n      <td>277</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Phoenix, AR</td>\n      <td>422</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Bakersfield, CA</td>\n      <td>471</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Albuquerque, NM</td>\n      <td>481</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Reno, NV</td>\n      <td>484</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Oklahoma City, OK</td>\n      <td>492</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Fresno, CA</td>\n      <td>498</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Des Moines, IA</td>\n      <td>527</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>New Orleans, LA</td>\n      <td>719</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>St. Louis, MO</td>\n      <td>763</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>San Antonio, TX</td>\n      <td>833</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Las Vegas, NV</td>\n      <td>840</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Portland,OR</td>\n      <td>930</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Santa Barbara, CA</td>\n      <td>938</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Houston, TX</td>\n      <td>950</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Colorado Springs, CO</td>\n      <td>984</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Detroit, MI</td>\n      <td>990</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Austin, TX</td>\n      <td>1007</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Fort Worth, Texas</td>\n      <td>1027</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Miami, FL</td>\n      <td>1034</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Dallas, TX</td>\n      <td>1036</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Orlando, FL</td>\n      <td>1067</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Tampa, FL</td>\n      <td>1092</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>San Diego, CA</td>\n      <td>1095</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>Atlanta, GA</td>\n      <td>1126</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>Sacramento, CA</td>\n      <td>1169</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>Denver, CO</td>\n      <td>1170</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>Seattle, WA</td>\n      <td>1220</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>Boston, MA</td>\n      <td>1313</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>Arlington, VA</td>\n      <td>1338</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>Chicago, IL</td>\n      <td>1342</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>Santa Rosa, CA</td>\n      <td>1428</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>Long Beach, CA</td>\n      <td>1533</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>Los Angeles, CA</td>\n      <td>1537</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>Palmdale, CA</td>\n      <td>1542</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>San Francisco, CA</td>\n      <td>1547</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>San Jose, CA</td>\n      <td>1549</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>Palo Alto, CA</td>\n      <td>1567</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>New Haven, CT</td>\n      <td>1597</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>New York, NY</td>\n      <td>1762</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    }, 
                    "execution_count": 9
                }
            ], 
            "execution_count": 9
        }, 
        {
            "source": "print('The city with the highest amount of venues matching your interests is: ' + str(max_city) +\n      ' with ' + str(max_number) + ' venues.')\nprint('The city with the lowest amount of venues matching your interests is: ' + str(min_city) +\n      ' with ' + str(min_number) + ' venues.')", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "The city with the highest amount of venues matching your interests is: New York, NY with 1762 venues.\nThe city with the lowest amount of venues matching your interests is: Anchorage, AK with 267 venues.\n"
                }
            ], 
            "execution_count": 10
        }, 
        {
            "source": "Let's find out which venue types are more relevant to include in our analysis", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# Create a dataframe that counts the total number of venues per type found.\nvenue_types_df = pd.DataFrame(venues_df.groupby('Type').count())", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 11
        }, 
        {
            "source": "venue_types_df.head()", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "                     City  CategoryID  Venue  Latitude  Longitude\nType                                                             \nAccessories Store       3           3      3         3          3\nAdvertising Agency      8           8      8         8          8\nAlternative Healer      3           3      3         3          3\nAmerican Restaurant    26          26     26        26         26\nAmphitheater            6           6      6         6          6", 
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>City</th>\n      <th>CategoryID</th>\n      <th>Venue</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n    </tr>\n    <tr>\n      <th>Type</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Accessories Store</th>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>Advertising Agency</th>\n      <td>8</td>\n      <td>8</td>\n      <td>8</td>\n      <td>8</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>Alternative Healer</th>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>American Restaurant</th>\n      <td>26</td>\n      <td>26</td>\n      <td>26</td>\n      <td>26</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>Amphitheater</th>\n      <td>6</td>\n      <td>6</td>\n      <td>6</td>\n      <td>6</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    }, 
                    "execution_count": 12
                }
            ], 
            "execution_count": 12
        }, 
        {
            "source": "We see here that some venues seem less significant than others, so we are going to filter out the least common types \nand create a list of the relevant types.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# delete types that don't meet a certain thresh\n\nrelevant_venues_df = venue_types_df[venue_types_df['City'] > 20]\nrelevant_venues_df = relevant_venues_df.reset_index()\nrelevant_venues_df.head()\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "                  Type  City  CategoryID  Venue  Latitude  Longitude\n0  American Restaurant    26          26     26        26         26\n1          Art Gallery    79          79     79        79         79\n2           Art Museum    24          24     24        24         24\n3           Art Studio   311         311    311       311        311\n4               Bakery    26          26     26        26         26", 
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Type</th>\n      <th>City</th>\n      <th>CategoryID</th>\n      <th>Venue</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>American Restaurant</td>\n      <td>26</td>\n      <td>26</td>\n      <td>26</td>\n      <td>26</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Art Gallery</td>\n      <td>79</td>\n      <td>79</td>\n      <td>79</td>\n      <td>79</td>\n      <td>79</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Art Museum</td>\n      <td>24</td>\n      <td>24</td>\n      <td>24</td>\n      <td>24</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Art Studio</td>\n      <td>311</td>\n      <td>311</td>\n      <td>311</td>\n      <td>311</td>\n      <td>311</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Bakery</td>\n      <td>26</td>\n      <td>26</td>\n      <td>26</td>\n      <td>26</td>\n      <td>26</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    }, 
                    "execution_count": 13
                }
            ], 
            "execution_count": 13
        }, 
        {
            "source": "# create a list of relevant venues", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 14
        }, 
        {
            "source": "relevant_types = relevant_venues_df['Type'].tolist()\nrelevant_types\n", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "['American Restaurant',\n 'Art Gallery',\n 'Art Museum',\n 'Art Studio',\n 'Bakery',\n 'Beach',\n 'Bike Shop',\n 'Bike Trail',\n 'Botanical Garden',\n 'Bridge',\n 'Buddhist Temple',\n 'Caf\u00e9',\n 'Campground',\n 'City',\n 'Coffee Shop',\n 'Convention Center',\n 'Dog Run',\n 'Event Space',\n 'Farm',\n 'Farmers Market',\n 'Field',\n 'Flower Shop',\n 'Food & Drink Shop',\n 'Forest',\n 'Fruit & Vegetable Store',\n 'Garden',\n 'Garden Center',\n 'General Entertainment',\n 'Gourmet Shop',\n 'Grocery Store',\n 'Health Food Store',\n 'Hindu Temple',\n 'Historic Site',\n 'History Museum',\n 'Hotel',\n 'Italian Restaurant',\n 'Juice Bar',\n 'Lake',\n 'Liquor Store',\n 'Market',\n 'Monument / Landmark',\n 'Mountain',\n 'Museum',\n 'National Park',\n 'Nature Preserve',\n 'Neighborhood',\n 'Observatory',\n 'Office',\n 'Organic Grocery',\n 'Other Great Outdoors',\n 'Park',\n 'Playground',\n 'Plaza',\n 'Resort',\n 'Restaurant',\n 'Road',\n 'Scenic Lookout',\n 'Shopping Mall',\n 'Ski Area',\n 'State / Provincial Park',\n 'Supermarket',\n 'Supplement Shop',\n 'Synagogue',\n 'Tech Startup',\n 'Temple',\n 'Theme Park',\n 'Trail',\n 'Vineyard',\n 'Wine Bar',\n 'Wine Shop',\n 'Winery',\n 'Zoo']"
                    }, 
                    "execution_count": 15
                }
            ], 
            "execution_count": 15
        }, 
        {
            "source": "#### Create final filtered dataframe", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "#Filter out irrelevant types from dataset\n# Create now the final dataframe where the irrelevant types are \ndf = venues_df\ndf = df.loc[df['Type'].isin(relevant_types)]\ndf.shape", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "(41038, 6)"
                    }, 
                    "execution_count": 16
                }
            ], 
            "execution_count": 16
        }, 
        {
            "source": "df.head()", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "          City                CategoryID                              Venue  \\\n0  Houston, TX  4bf58dd8d48988d159941735                 Buffalo Bayou Walk   \n1  Houston, TX  4bf58dd8d48988d159941735                 Buffalo Bayou Park   \n2  Houston, TX  4bf58dd8d48988d159941735  Houston Arboretum & Nature Center   \n3  Houston, TX  4bf58dd8d48988d159941735                 Herman Park Trails   \n4  Houston, TX  4bf58dd8d48988d159941735                 Terry Hershey Park   \n\n    Latitude  Longitude              Type  \n0  29.762177 -95.375844             Trail  \n1  29.762068 -95.391626              Park  \n2  29.765361 -95.452177  Botanical Garden  \n3  29.719804 -95.388748             Trail  \n4  29.779138 -95.623096              Park  ", 
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>City</th>\n      <th>CategoryID</th>\n      <th>Venue</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>Type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Houston, TX</td>\n      <td>4bf58dd8d48988d159941735</td>\n      <td>Buffalo Bayou Walk</td>\n      <td>29.762177</td>\n      <td>-95.375844</td>\n      <td>Trail</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Houston, TX</td>\n      <td>4bf58dd8d48988d159941735</td>\n      <td>Buffalo Bayou Park</td>\n      <td>29.762068</td>\n      <td>-95.391626</td>\n      <td>Park</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Houston, TX</td>\n      <td>4bf58dd8d48988d159941735</td>\n      <td>Houston Arboretum &amp; Nature Center</td>\n      <td>29.765361</td>\n      <td>-95.452177</td>\n      <td>Botanical Garden</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Houston, TX</td>\n      <td>4bf58dd8d48988d159941735</td>\n      <td>Herman Park Trails</td>\n      <td>29.719804</td>\n      <td>-95.388748</td>\n      <td>Trail</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Houston, TX</td>\n      <td>4bf58dd8d48988d159941735</td>\n      <td>Terry Hershey Park</td>\n      <td>29.779138</td>\n      <td>-95.623096</td>\n      <td>Park</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    }, 
                    "execution_count": 17
                }
            ], 
            "execution_count": 17
        }, 
        {
            "source": "### 7. Format Foursquare Data for Plotting", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Prepare the data for plotting.\nCreate various slices of the data for input in a horizontal bar chart.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# Create dataframes for each venue category\n\noutdoors_df = df.loc[df['CategoryID'].isin(outdoors_venues_ID)]\nstartups_df = df.loc[df['CategoryID'].isin(professional_venues_ID)]\ncultural_df = df.loc[df['CategoryID'].isin(cultural_venues_ID)]\nfood_df = df.loc[df['CategoryID'].isin(food_venues_ID)]\nbeauty_df = df.loc[df['CategoryID'].isin(beauty_venues_ID)]\nprint('Done')", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Done\n"
                }
            ], 
            "execution_count": 18
        }, 
        {
            "source": "# Count the numbers of venues in each category.\noutdoors_count = pd.DataFrame(outdoors_df.groupby('City').count()['Venue'])\noutdoors_count = outdoors_count.reindex(venues_count['City'])\nstartups_count = pd.DataFrame(startups_df.groupby('City').count()['Venue'])\nstartups_count = startups_count.reindex(venues_count['City'])\ncultural_count = pd.DataFrame(cultural_df.groupby('City').count()['Venue'])\ncultural_count = cultural_count.reindex(venues_count['City'])\nfood_count = pd.DataFrame(food_df.groupby('City').count()['Venue'])\nfood_count = food_count.reindex(venues_count['City'])\nbeauty_count = pd.DataFrame(beauty_df.groupby('City').count()['Venue'])\nbeauty_count = beauty_count.reindex(venues_count['City'])\nprint('Done')", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Done\n"
                }
            ], 
            "execution_count": 19
        }, 
        {
            "source": "# Create a function to count how many of each category are present per city\n\ndef makeList(cities, count_df):\n    N = len(cities)\n    count_list = []\n    for index in range(0,N):\n        city_total = count_df.iloc[index][0]\n        count_list.append(city_total)\n    return count_list\nprint('Done')", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Done\n"
                }
            ], 
            "execution_count": 20
        }, 
        {
            "source": "# Apply the function to create lists of total venues per category\noutdoors_count_list = makeList(cities, outdoors_count)\nstartups_count_list = makeList(cities, startups_count)\ncultural_count_list = makeList(cities, cultural_count)\nfood_count_list = makeList(cities, food_count)\nbeauty_count_list = makeList(cities, beauty_count)\nprint('Done')\n\n# YOU HAVE TO ORDER THIS DATAFRAME BY THE ORDER OF VENUE_COUNT", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Done\n"
                }
            ], 
            "execution_count": 21
        }, 
        {
            "source": "py.sign_in('tinaprisma','bti38jh0wvCmy3lmrJ95')", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 22
        }, 
        {
            "source": "### 8. Plot Foursquare Data", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "import plotly.plotly as py\nimport plotly.graph_objs as go\n\ntrace1 = go.Bar(\n    y= cities[0:20],\n    x= outdoors_count_list[0:20],\n    name='Outdoors',\n    orientation = 'h',\n    marker = dict(\n        color = 'rgba(73,124,81,0.8)',\n    )\n)\ntrace2 = go.Bar(\n    y= cities[0:20],\n    x= startups_count_list[0:20],\n    name='Startups',\n    orientation = 'h',\n    marker = dict(\n        color = 'rgba(81,73,124,0.8)'\n   )\n)\ntrace3 = go.Bar(\n    y= cities[0:20],\n    x= cultural_count_list[0:20],\n    name='Cultural',\n    orientation = 'h',\n    marker = dict(\n        color = 'rgba(124,73,116,0.8)',\n   )\n)\ntrace4 = go.Bar(\n    y= cities[0:20],\n    x= food_count_list[0:20],\n    name='Food',\n    orientation = 'h',\n    marker = dict(\n        color = 'rgba(139,115,95,0.8)',\n    )\n)\ntrace5 = go.Bar(\n    y= cities[0:20],\n    x= beauty_count_list[0:20],\n    name='Beauty',\n    orientation = 'h',\n    marker = dict(\n        color = 'rgba(95,119,139,0.8)',\n    )\n)       \ndata = [trace1, trace2, trace3, trace4, trace5]\nlayout = go.Layout(\n    barmode='stack', title = 'Foursquare Venue Categories in U.S. Cities',xaxis=dict(range=[0, 1800]))\n\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig, filename='marker-h-bar')", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/html": "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~tinaprisma/2.embed\" height=\"525px\" width=\"100%\"></iframe>", 
                        "text/plain": "<plotly.tools.PlotlyDisplay object>"
                    }, 
                    "execution_count": 126, 
                    "metadata": {}
                }
            ], 
            "execution_count": 126
        }, 
        {
            "source": "import plotly.plotly as py\nimport plotly.graph_objs as go\n\ntracea = go.Bar(\n    y= cities[20:42],\n    x= outdoors_count_list[20:42],\n    name='Outdoors',\n    orientation = 'h',\n    marker = dict(\n        color = 'rgba(73,124,81,0.8)',\n    )\n)\ntraceb = go.Bar(\n    y= cities[20:42],\n    x= startups_count_list[20:42],\n    name='Startups',\n    orientation = 'h',\n    marker = dict(\n        color = 'rgba(81,73,124,0.8)'\n   )\n)\ntracec = go.Bar(\n    y= cities[20:42],\n    x= cultural_count_list[20:42],\n    name='Cultural',\n    orientation = 'h',\n    marker = dict(\n        color = 'rgba(124,73,116,0.8)',\n   )\n)\ntraced = go.Bar(\n    y= cities[20:42],\n    x= food_count_list[20:42],\n    name='Food',\n    orientation = 'h',\n    marker = dict(\n        color = 'rgba(139,115,95,0.8)',\n    )\n)\ntracee = go.Bar(\n    y= cities[20:42],\n    x= beauty_count_list[20:42],\n    name='Beauty',\n    orientation = 'h',\n    marker = dict(\n        color = 'rgba(95,119,139,0.8)',\n    )\n)\n\ndata2 = [tracea, traceb, tracec, traced, tracee]\nlayout2 = go.Layout(\n    barmode='stack', title = 'Foursquare Venue Categories in U.S. Cities continued',xaxis=dict(range=[0, 1800])\n)\n\nfig2 = go.Figure(data=data2, layout=layout2)\npy.iplot(fig2, filename='marker-h2-bar')", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/html": "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~tinaprisma/2.embed\" height=\"525px\" width=\"100%\"></iframe>", 
                        "text/plain": "<plotly.tools.PlotlyDisplay object>"
                    }, 
                    "execution_count": 129, 
                    "metadata": {}
                }
            ], 
            "execution_count": 129
        }, 
        {
            "source": "We observe that there are more startups than the limit imposed by Foursquare. WE could add more points inside the city, or we can rely on data points that are more predicitive.\nAccording to this analysis, Houston and Denver look very similar, but we know this is not the case.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### 9. Scrape Temperature Data for Each City and Compare Plots", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Temperature data was scraped from a US government dataset (NOAA.gov)\n\nTo do this, we first had to research the city codes for each of our cities.\n\nThen, we had to understand the structure of the data as it was published.\n\nWe found out that there was a pattern in the URLs that we could leverage to scrape automatically lots of data.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "city_codes = ['USW00012918','USW00013958','USW00093037','USW00024233','USW00023234','USW00024229']\n#these correspond to the order found in our list, cities.\n\ntemp_measures = ['tmin', 'tavg', 'tmax']\n\ntemperatures_df = pd.DataFrame()\n\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 25
        }, 
        {
            "source": "# This function creates a list of URLs where NOAA.gov stores temperature data for the month of August between the years 2000-2019 \n# August will be a proxy for Summer Temperatures\n\ndef extractAugURL(city_codes, temp_measures):\n    \n    aug_temps_city_list=[]\n    \n    for c in range(0,len(city_codes)):\n        aug_url_list = []\n        for t in range(0,len(temp_measures)):\n            aug_url = 'https://www.ncdc.noaa.gov/cag/city/time-series/' + city_codes[c] + '-' + temp_measures[t] + '-1-8-2000-2019.csv' #scrape august data\n            #aug_url_list.append(aug_url)\n            aug_temps_city_list.append(aug_url)\n       \n    return aug_temps_city_list\n   \n# This function creates a list of URLs where NOAA.gov stores temperature data for the month of February between the years 2000-2019 \n# February will be a proxy for Winter Temperatures\n\ndef extractFebURL(city_codes, temp_measures):\n    \n    feb_temps_city_list=[]\n    \n    for c in range(0,len(city_codes)):\n        feb_url_list = []\n        for t in range(0,len(temp_measures)):\n            feb_url = 'https://www.ncdc.noaa.gov/cag/city/time-series/' + city_codes[c] + '-' + temp_measures[t] + '-1-2-2000-2019.csv' #scrape FEBR data\n            feb_temps_city_list.append(feb_url)\n        \n    return feb_temps_city_list\n   ", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 26
        }, 
        {
            "source": "# Create a list of URLS for each city and season, making use of the above functions\naug_urls = extractAugURL(city_codes, temp_measures)\nfeb_urls = extractFebURL(city_codes, temp_measures)", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "execution_count": 27
        }, 
        {
            "source": "# Extract the August Temperature Data CSV file from NOAA.gov and store it as a dataframe\n# Create a list of dataframes that will later be filtered for each City\naug_master_list = []  # created a list with aaaallll the dataframes \nfor url in range(0,len(aug_urls)):\n    aug_df = pd.read_csv(aug_urls[url])\n    aug_df = aug_df.drop([0,1,2])\n    aug_df = aug_df.reset_index()\n    aug_df = aug_df.drop(aug_df.columns[-1], axis=1)\n    aug_df = aug_df.drop(aug_df.columns[-1], axis=1)\n    aug_df = aug_df.drop(aug_df.columns[0], axis=1)\n    aug_master_list.append(aug_df)\nprint('Done')", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Done\n"
                }
            ], 
            "execution_count": 28
        }, 
        {
            "source": "# Extract the February Temperature Data CSV file from NOAA.gov and store it as a dataframe\n# Create a list of dataframes that will later be filtered for each City\n\nfeb_master_list = []  \nfor url in range(0,len(feb_urls)):\n    feb_df = pd.read_csv(feb_urls[url])\n    feb_df = feb_df.drop([0,1,2])\n    feb_df = feb_df.reset_index()\n    feb_df = feb_df.drop(feb_df.columns[-1], axis=1)\n    feb_df = feb_df.drop(feb_df.columns[-1], axis=1)\n    feb_df = feb_df.drop(feb_df.columns[0], axis=1)\n    feb_master_list.append(feb_df)\nprint('Done')", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Done\n"
                }
            ], 
            "execution_count": 29
        }, 
        {
            "source": "# This function returns a dataframe for each US City analysed containing organized temperature data\n\ndef createCityTempDF(feb_master_list, aug_master_list, start_index):\n    df = pd.DataFrame()\n    list1=[]\n    list1a=[]\n    list2=[]\n    list3=[]\n    list4=[]\n    list5=[]\n    list6=[]\n    i1 = start_index\n    i2 = start_index + 1\n    i3 = start_index + 2\n    for num in range(0,19):\n        df1 = feb_master_list[i1]\n        df2 = feb_master_list[i2]\n        df3 = feb_master_list[i3]\n        df4 = aug_master_list[i1]\n        df5 = aug_master_list[i2]\n        df6 = aug_master_list[i3]\n        list1.append(df1.iloc[num][0])\n        list1a.append(df1.iloc[num][1])\n        list2.append(df2.iloc[num][1])\n        list3.append(df3.iloc[num][1])\n        list4.append(df4.iloc[num][1])\n        list5.append(df5.iloc[num][1])\n        list6.append(df6.iloc[num][1])\n    df['Date'] = pd.Series(list1, index = df1.index[:len(list1)])\n    df['Feb Minimum'] = pd.Series(list1a, index = df1.index[:len(list2)]) \n    df['Feb Average'] = pd.Series(list2, index = df2.index[:len(list3)])\n    df['Feb Maximum'] = pd.Series(list3, index = df3.index[:len(list4)]) \n    df['Aug Minimum'] = pd.Series(list4, index = df4.index[:len(list2)]) \n    df['Aug Average'] = pd.Series(list5, index = df5.index[:len(list3)])\n    df['Aug Maximum'] = pd.Series(list6, index = df6.index[:len(list4)])\n    return df\n    ", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 30
        }, 
        {
            "source": "Extract Temperature Data for Each City and Store in dataframe", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "hou_temp_df = createCityTempDF(feb_master_list, aug_master_list, 0)\naus_temp_df = createCityTempDF(feb_master_list, aug_master_list, 3)\nden_temp_df = createCityTempDF(feb_master_list, aug_master_list, 6)\nsea_temp_df = createCityTempDF(feb_master_list, aug_master_list, 9)\nsan_temp_df = createCityTempDF(feb_master_list, aug_master_list, 12)\npor_temp_df = createCityTempDF(feb_master_list, aug_master_list, 15)\nprint('This is an example of the resulting dataframe:')\npor_temp_df", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "This is an example of the resulting dataframe:\n"
                }, 
                {
                    "output_type": "execute_result", 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "      Date Feb Minimum Feb Average Feb Maximum Aug Minimum Aug Average  \\\n0   200002        37.1        43.7        50.3        56.9        67.8   \n1   200102        33.6        42.0        50.3        58.3        69.2   \n2   200202        36.3        44.4        52.4        57.2        69.3   \n3   200302        37.0        44.3        51.6        58.4        70.1   \n4   200402        38.8        45.2        51.7        60.7        71.5   \n5   200502        33.2        43.5        53.8        58.1        70.7   \n6   200602        34.7        42.0        49.3        57.1        69.2   \n7   200702        38.0        44.2        50.4        58.0        68.3   \n8   200802        37.3        44.9        52.4        59.2        69.6   \n9   200902        32.4        41.3        50.3        59.3        69.9   \n10  201002        39.0        46.6        54.1        56.8        68.1   \n11  201102        34.1        40.3        46.5        59.2        69.9   \n12  201202        37.7        43.4        49.0        58.9        71.1   \n13  201302        38.1        44.4        50.7        60.9        71.2   \n14  201402        34.7        40.4        46.0        61.4        73.1   \n15  201502        41.5        49.2        56.8        60.5        72.4   \n16  201602        42.2        49.3        56.4        59.3        71.9   \n17  201702        34.8        40.8        46.8        60.2        73.6   \n18  201802        36.0        42.5        49.0        60.0        72.2   \n\n   Aug Maximum  \n0         78.7  \n1         80.1  \n2         81.4  \n3         81.7  \n4         82.3  \n5         83.3  \n6         81.2  \n7         78.5  \n8         80.0  \n9         80.5  \n10        79.5  \n11        80.5  \n12        83.3  \n13        81.5  \n14        84.8  \n15        84.3  \n16        84.5  \n17        87.1  \n18        84.3  ", 
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Feb Minimum</th>\n      <th>Feb Average</th>\n      <th>Feb Maximum</th>\n      <th>Aug Minimum</th>\n      <th>Aug Average</th>\n      <th>Aug Maximum</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>200002</td>\n      <td>37.1</td>\n      <td>43.7</td>\n      <td>50.3</td>\n      <td>56.9</td>\n      <td>67.8</td>\n      <td>78.7</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>200102</td>\n      <td>33.6</td>\n      <td>42.0</td>\n      <td>50.3</td>\n      <td>58.3</td>\n      <td>69.2</td>\n      <td>80.1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>200202</td>\n      <td>36.3</td>\n      <td>44.4</td>\n      <td>52.4</td>\n      <td>57.2</td>\n      <td>69.3</td>\n      <td>81.4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>200302</td>\n      <td>37.0</td>\n      <td>44.3</td>\n      <td>51.6</td>\n      <td>58.4</td>\n      <td>70.1</td>\n      <td>81.7</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>200402</td>\n      <td>38.8</td>\n      <td>45.2</td>\n      <td>51.7</td>\n      <td>60.7</td>\n      <td>71.5</td>\n      <td>82.3</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>200502</td>\n      <td>33.2</td>\n      <td>43.5</td>\n      <td>53.8</td>\n      <td>58.1</td>\n      <td>70.7</td>\n      <td>83.3</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>200602</td>\n      <td>34.7</td>\n      <td>42.0</td>\n      <td>49.3</td>\n      <td>57.1</td>\n      <td>69.2</td>\n      <td>81.2</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>200702</td>\n      <td>38.0</td>\n      <td>44.2</td>\n      <td>50.4</td>\n      <td>58.0</td>\n      <td>68.3</td>\n      <td>78.5</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>200802</td>\n      <td>37.3</td>\n      <td>44.9</td>\n      <td>52.4</td>\n      <td>59.2</td>\n      <td>69.6</td>\n      <td>80.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>200902</td>\n      <td>32.4</td>\n      <td>41.3</td>\n      <td>50.3</td>\n      <td>59.3</td>\n      <td>69.9</td>\n      <td>80.5</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>201002</td>\n      <td>39.0</td>\n      <td>46.6</td>\n      <td>54.1</td>\n      <td>56.8</td>\n      <td>68.1</td>\n      <td>79.5</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>201102</td>\n      <td>34.1</td>\n      <td>40.3</td>\n      <td>46.5</td>\n      <td>59.2</td>\n      <td>69.9</td>\n      <td>80.5</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>201202</td>\n      <td>37.7</td>\n      <td>43.4</td>\n      <td>49.0</td>\n      <td>58.9</td>\n      <td>71.1</td>\n      <td>83.3</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>201302</td>\n      <td>38.1</td>\n      <td>44.4</td>\n      <td>50.7</td>\n      <td>60.9</td>\n      <td>71.2</td>\n      <td>81.5</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>201402</td>\n      <td>34.7</td>\n      <td>40.4</td>\n      <td>46.0</td>\n      <td>61.4</td>\n      <td>73.1</td>\n      <td>84.8</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>201502</td>\n      <td>41.5</td>\n      <td>49.2</td>\n      <td>56.8</td>\n      <td>60.5</td>\n      <td>72.4</td>\n      <td>84.3</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>201602</td>\n      <td>42.2</td>\n      <td>49.3</td>\n      <td>56.4</td>\n      <td>59.3</td>\n      <td>71.9</td>\n      <td>84.5</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>201702</td>\n      <td>34.8</td>\n      <td>40.8</td>\n      <td>46.8</td>\n      <td>60.2</td>\n      <td>73.6</td>\n      <td>87.1</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>201802</td>\n      <td>36.0</td>\n      <td>42.5</td>\n      <td>49.0</td>\n      <td>60.0</td>\n      <td>72.2</td>\n      <td>84.3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    }, 
                    "execution_count": 31
                }
            ], 
            "execution_count": 31
        }, 
        {
            "source": "### 10. Plot Temperature Data", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# Store Temperatures in variables in preparation for the plot.\n\nimport plotly.plotly as py\nimport plotly.graph_objs as go\n\nx = list(range(0,19))\nx_rev = x[::-1]\n\n# Houston Summer Temperatures\ny1 = list(hou_temp_df['Aug Average'])\ny1_upper = list(hou_temp_df['Aug Maximum'])\ny1_lower = list(hou_temp_df['Aug Minimum'])\ny1_lower = y1_lower[::-1]\n\n# Houston Summer Avg T\ntrace1 = go.Scatter(\n    x=x,\n    y=y1,\n    line=dict(color='rgb(73,124,81)'),\n    mode='lines',\n    name='\u00b0F (Summer)',\n    showlegend=False\n)\n# Houston Summer Hi & Lo T\ntrace2 = go.Scatter(\n    x=x+x_rev,\n    y=y1_upper+y1_lower,\n    fill='tozerox',\n    fillcolor='rgba(73,124,81,0.2)',\n    line=dict(color='rgba(255,255,255,0)'),\n    showlegend=False,\n    hoverinfo='none'\n)\n\n# Houston Winter Temperatures \ny2 = list(hou_temp_df['Feb Average'])\ny2_upper = list(hou_temp_df['Feb Maximum'])\ny2_lower = list(hou_temp_df['Feb Minimum'])\ny2_lower = y2_lower[::-1]\n\n# Houston Winter Line Average\ntrace3 = go.Scatter(\n    x=x,\n    y=y2,\n    line=dict(color='rgb(73,124,81)'),\n    mode='lines',\n    name='\u00b0F (Winter)',\n    showlegend=False,\n)\n# Houston Winter High and Low\ntrace4 = go.Scatter(\n    x=x+x_rev,\n    y=y2_upper+y2_lower,\n    fill='tozerox',\n    fillcolor='rgba(73,124,81,0.2)',\n    line=dict(color='rgba(255,255,255,0)'),\n    showlegend=False,\n    hoverinfo='none'\n)\n\n# Austin Summer Temperatures\ny3 = list(aus_temp_df['Aug Average'])\ny3_upper = list(aus_temp_df['Aug Maximum'])\ny3_lower = list(aus_temp_df['Aug Minimum'])\ny3_lower = y3_lower[::-1]\n\n# Austin Summer Avg T\ntrace5 = go.Scatter(\n    x=x,\n    y=y3,\n    line=dict(color='rgb(81,73,124)'),\n    mode='lines',\n    name='\u00b0F (Summer)',\n    showlegend=False\n)\n\n# Austin Summer Hi & Lo T\ntrace6 = go.Scatter(\n    x=x+x_rev,\n    y=y3_upper+y3_lower,\n    fill='tozerox',\n    fillcolor='rgba(81,73,124,0.2)',\n    line=dict(color='rgba(255,255,255,0)'),\n    showlegend=False,\n    hoverinfo='none'\n)\n\n# Austin Winter Temperatures\ny4 = list(aus_temp_df['Feb Average'])\ny4_upper = list(aus_temp_df['Feb Maximum'])\ny4_lower = list(aus_temp_df['Feb Minimum'])\ny4_lower = y4_lower[::-1]\n\n# Austin Winter Average T\ntrace7 = go.Scatter(\n    x=x,\n    y=y4,\n    line=dict(color='rgb(81,73,124)'),\n    mode='lines',\n    name='\u00b0F (Winter)',\n    showlegend=False,\n)\n# Austin Winter Hi & Lo T\ntrace8 = go.Scatter(\n    x=x+x_rev,\n    y=y4_upper+y4_lower,\n    fill='tozerox',\n    fillcolor='rgba(81,73,124,0.2)',\n    line=dict(color='rgba(255,255,255,0)'),\n    showlegend=False,\n    hoverinfo='none'\n)\n# Denver Summer Temperatures\ny5 = list(den_temp_df['Aug Average'])\ny5_upper = list(den_temp_df['Aug Maximum'])\ny5_lower = list(den_temp_df['Aug Minimum'])\ny5_lower = y5_lower[::-1]\n\n# Denver Summer Average T\ntrace9 = go.Scatter(\n    x=x,\n    y=y5,\n    line=dict(color='rgb(124,73,116)'),\n    mode='lines',\n    name='\u00b0F (Summer)',\n    showlegend=False\n)\n# Denver Summer Hi & Lo T\ntrace10 = go.Scatter(\n    x=x+x_rev,\n    y=y5_upper+y5_lower,\n    fill='tozerox',\n    fillcolor='rgba(124,73,116,0.2)',\n    line=dict(color='rgba(255,255,255,0)'),\n    showlegend=False,\n    hoverinfo='none'\n)\n\n# Denver Winter Temperatures\ny6 = list(den_temp_df['Feb Average'])\ny6_upper = list(den_temp_df['Feb Maximum'])\ny6_lower = list(den_temp_df['Feb Minimum'])\ny6_lower = y6_lower[::-1]\n\n# Denver Winter Average T\ntrace11 = go.Scatter(\n    x=x,\n    y=y6,\n    line=dict(color='rgb(124,73,116)'),\n    mode='lines',\n    name='\u00b0F (Winter)',\n    showlegend=False,\n)\n# Denver Winter Hi & Lo T\ntrace12 = go.Scatter(\n    x=x+x_rev,\n    y=y6_upper+y6_lower,\n    fill='tozerox',\n    fillcolor='rgba(124,73,116,0.2)',\n    line=dict(color='rgba(255,255,255,0)'),\n    showlegend=False,\n    hoverinfo='none'\n)\n\n\n# Seattle Summer Temperature\ny7 = list(sea_temp_df['Aug Average'])\ny7_upper = list(sea_temp_df['Aug Maximum'])\ny7_lower = list(sea_temp_df['Aug Minimum'])\ny7_lower = y7_lower[::-1]\n\n# Seattle Summer Average T\ntrace13 = go.Scatter(\n    x=x,\n    y=y7,\n    line=dict(color='rgb(124,73,116)'),\n    mode='lines',\n    name='\u00b0F (Summer)',\n    showlegend=False\n)\n# Seattle Summer Hi & Lo T\ntrace14 = go.Scatter(\n    x=x+x_rev,\n    y=y7_upper+y7_lower,\n    fill='tozerox',\n    fillcolor='rgba(124,73,116,0.2)',\n    line=dict(color='rgba(255,255,255,0)'),\n    showlegend=False,\n    hoverinfo='none'\n)\n\n# Seattle Winter Temperatures\ny8 = list(sea_temp_df['Feb Average'])\ny8_upper = list(sea_temp_df['Feb Maximum'])\ny8_lower = list(sea_temp_df['Feb Minimum'])\ny8_lower = y8_lower[::-1]\n\n# Seattle Winter Average T\ntrace15 = go.Scatter(\n    x=x,\n    y=y8,\n    line=dict(color='rgb(124,73,116)'),\n    mode='lines',\n    name='\u00b0F (Winter)',\n    showlegend=False,\n)\n# Seattle Winter Hi & Lo T\ntrace16 = go.Scatter(\n    x=x+x_rev,\n    y=y8_upper+y8_lower,\n    fill='tozerox',\n    fillcolor='rgba(124,73,116,0.2)',\n    line=dict(color='rgba(255,255,255,0)'),\n    showlegend=False,\n    hoverinfo='none'\n)\n# San Francisco Summer Temperatures\ny9 = list(san_temp_df['Aug Average'])\ny9_upper = list(san_temp_df['Aug Maximum'])\ny9_lower = list(san_temp_df['Aug Minimum'])\ny9_lower = y9_lower[::-1]\n\n# San Francisco Summer Average T\ntrace17 = go.Scatter(\n    x=x,\n    y=y9,\n    line=dict(color='rgb(139,115,95)'),\n    mode='lines',\n    name='\u00b0F (Summer)',\n    showlegend=False\n)\n# San Francisco Summer Hi & Lo T\ntrace18 = go.Scatter(\n    x=x+x_rev,\n    y=y9_upper+y9_lower,\n    fill='tozerox',\n    fillcolor='rgba(139,115,95,0.2)',\n    line=dict(color='rgba(255,255,255,0)'),\n    showlegend=False,\n    hoverinfo='none'\n)\n\n# San Francisco Winter Temperatures\ny10 = list(san_temp_df['Feb Average'])\ny10_upper = list(san_temp_df['Feb Maximum'])\ny10_lower = list(san_temp_df['Feb Minimum'])\ny10_lower = y10_lower[::-1]\n\n# San Francisco Winter Average T\ntrace19 = go.Scatter(\n    x=x,\n    y=y10,\n    line=dict(color='rgb(139,115,95)'),\n    mode='lines',\n    name='\u00b0F (Winter)',\n    showlegend=False,\n)\n# San Francisco Winter Hi & Lo T\ntrace20 = go.Scatter(\n    x=x+x_rev,\n    y=y10_upper+y10_lower,\n    fill='tozerox',\n    fillcolor='rgba(139,115,95,0.2)',\n    line=dict(color='rgba(255,255,255,0)'),\n    showlegend=False,\n    hoverinfo='none'\n)\n\n# Portland Summer Temperatures\ny11= list(por_temp_df['Aug Average'])\ny11_upper = list(por_temp_df['Aug Maximum'])\ny11_lower = list(por_temp_df['Aug Minimum'])\ny11_lower = y11_lower[::-1]\n\n# Portland Summer Average T\ntrace21 = go.Scatter(\n    x=x,\n    y=y11,\n    line=dict(color='rgb(95,119,139)'),\n    mode='lines',\n    name='\u00b0F (Summer)',\n    showlegend=False\n)\n# Portland Summer Hi & Lo T\ntrace22 = go.Scatter(\n    x=x+x_rev,\n    y=y11_upper+y11_lower,\n    fill='tozerox',\n    fillcolor='rgba(95,119,139,0.2)',\n    line=dict(color='rgba(255,255,255,0)'),\n    showlegend=False,\n    hoverinfo='none'\n)\n# Portland Winter Temperatures\ny12 = list(por_temp_df['Feb Average'])\ny12_upper = list(por_temp_df['Feb Maximum'])\ny12_lower = list(por_temp_df['Feb Minimum'])\ny12_lower = y12_lower[::-1]\n\n# Portland Winter Average T\ntrace23 = go.Scatter(\n    x=x,\n    y=y12,\n    line=dict(color='rgb(95,119,139)'),\n    mode='lines',\n    name='\u00b0F (Winter)',\n    showlegend=False,\n)\n\n# Portland Winter Hi and Lo T\ntrace24 = go.Scatter(\n    x=x+x_rev,\n    y=y12_upper+y12_lower,\n    fill='tozerox',\n    fillcolor='rgba(95,119,139,0.2)',\n    line=dict(color='rgba(255,255,255,0)'),\n    showlegend=False,\n    hoverinfo='none'\n)\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 66
        }, 
        {
            "source": "# Set the layout and append lines for plotting\n\ndata = [trace1, trace2, trace3, trace4, trace5, trace6, trace7, trace8, trace9, trace10, trace11, trace12,\n        trace13, trace14, trace15, trace16, trace17, trace18, trace19, trace20, trace21, trace22, trace23, trace24]\n\n\nfig = tools.make_subplots(rows=3, cols=2, subplot_titles=('Houston', 'Austin',\n                                                          'Denver', 'Seattle',\n                                                          'San Francisco','Portland'))\nfig.append_trace(trace1, 1, 1)\nfig.append_trace(trace2, 1, 1)\nfig.append_trace(trace3, 1, 1)\nfig.append_trace(trace4, 1, 1)\nfig.append_trace(trace5, 1, 2)\nfig.append_trace(trace6, 1, 2)\nfig.append_trace(trace7, 1, 2)\nfig.append_trace(trace8, 1, 2)\nfig.append_trace(trace9, 2, 1)\nfig.append_trace(trace10, 2, 1)\nfig.append_trace(trace11, 2, 1)\nfig.append_trace(trace12, 2, 1)\nfig.append_trace(trace13, 2, 2)\nfig.append_trace(trace14, 2, 2)\nfig.append_trace(trace15, 2, 2)\nfig.append_trace(trace16, 2, 2)\nfig.append_trace(trace17, 3, 1)\nfig.append_trace(trace18, 3, 1)\nfig.append_trace(trace19, 3, 1)\nfig.append_trace(trace20, 3, 1)\nfig.append_trace(trace21, 3, 2)\nfig.append_trace(trace22, 3, 2)\nfig.append_trace(trace23, 3, 2)\nfig.append_trace(trace24, 3, 2)\n\nfig['layout'].update(title='Summer & Winter Temperatures in U.S. Cities (2000-2018)')\n\npy.iplot(fig)\n", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "This is the format of your plot grid:\n[ (1,1) x1,y1 ]  [ (1,2) x2,y2 ]\n[ (2,1) x3,y3 ]  [ (2,2) x4,y4 ]\n[ (3,1) x5,y5 ]  [ (3,2) x6,y6 ]\n\n"
                }, 
                {
                    "output_type": "execute_result", 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "<plotly.tools.PlotlyDisplay object>", 
                        "text/html": "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~tinaprisma/61.embed\" height=\"525px\" width=\"100%\"></iframe>"
                    }, 
                    "execution_count": 67
                }
            ], 
            "execution_count": 67
        }, 
        {
            "source": "### 10. Scrape Precipitation Data and Plot", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# This function creates URLs used to scrape data automatically\ndef extractRainURL(city_codes):\n    \n    precipitation_list = []\n    \n    for c in range(0,len(city_codes)):\n        \n        pre_url = 'https://www.ncdc.noaa.gov/cag/city/time-series/' + city_codes[c] + '-pcp-12-12-2000-2019.csv' #scrape august data\n            #aug_url_list.append(aug_url)\n        precipitation_list.append(pre_url)\n       \n    return precipitation_list", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 37
        }, 
        {
            "source": "# This block extracts the precipitation data CSV files from NOAA.gov and creates a list of dataframes\nprecipitation_urls = extractRainURL(city_codes)\nprecipitation_master_list = []  # created a list with aaaallll the dataframes \nfor url in range(0,len(precipitation_urls)):\n    pre_df = pd.read_csv(precipitation_urls[url])\n    pre_df = pre_df.drop([0,1,2])\n    pre_df = pre_df.reset_index()\n    pre_df = pre_df.drop(pre_df.columns[-1], axis=1)\n    pre_df = pre_df.drop(pre_df.columns[-1], axis=1)\n    pre_df = pre_df.drop(pre_df.columns[0], axis=1)\n    precipitation_master_list.append(pre_df)\nprint('Done')", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Done\n"
                }
            ], 
            "execution_count": 38
        }, 
        {
            "source": "# this function creates a dataframe of precipitation data for a city at the \"start index\"\ndef createCityTempDF(precipitation_master_list, start_index):\n    df = pd.DataFrame()\n    list=[]\n    i1 = start_index\n    for num in range(0,19):\n        df = precipitation_master_list[i1]\n        list.append(df.iloc[num][1])\n    df['Precipitation'] = pd.Series(list, index = df.index[:len(list)])\n    return df\n    ", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 39
        }, 
        {
            "source": "precipitation_master_list", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "[   Houston  Texas\n 0   200012  45.81\n 1   200112  81.69\n 2   200212  58.89\n 3   200312  45.18\n 4   200412  56.16\n 5   200512  35.74\n 6   200612  62.15\n 7   200712  68.09\n 8   200812  56.28\n 9   200912  52.59\n 10  201012  47.02\n 11  201112  25.39\n 12  201212  51.87\n 13  201312  43.08\n 14  201412  41.17\n 15  201512  77.14\n 16  201612  56.85\n 17  201712  79.19\n 18  201812  52.52,     Austin  Texas\n 0   200012  37.30\n 1   200112  42.89\n 2   200212  36.04\n 3   200312  21.43\n 4   200412  52.28\n 5   200512  22.36\n 6   200612  34.72\n 7   200712  46.94\n 8   200812  16.09\n 9   200912  31.40\n 10  201012  37.76\n 11  201112  19.69\n 12  201212  33.02\n 13  201312  41.05\n 14  201412  35.56\n 15  201512  59.98\n 16  201612  38.87\n 17  201712  34.73\n 18  201812  40.55,    Colorado Springs  Colorado\n 0            200012     16.92\n 1            200112     15.02\n 2            200212      7.89\n 3            200312     12.44\n 4            200412     21.14\n 5            200512     11.87\n 6            200612     13.87\n 7            200712     11.82\n 8            200812     12.97\n 9            200912     15.76\n 10           201012      9.40\n 11           201112     16.26\n 12           201212      8.13\n 13           201312     19.24\n 14           201412     17.07\n 15           201512     25.29\n 16           201612     14.37\n 17           201712     18.47\n 18           201812     15.45,    Seattle  Washington\n 0   200012       28.68\n 1   200112       37.60\n 2   200212       31.41\n 3   200312       41.82\n 4   200412       31.10\n 5   200512       35.48\n 6   200612       48.46\n 7   200712       39.01\n 8   200812       30.78\n 9   200912       38.46\n 10  201012       47.04\n 11  201112       36.42\n 12  201212       48.27\n 13  201312       32.60\n 14  201412       48.54\n 15  201512       44.85\n 16  201612       45.21\n 17  201712       47.94\n 18  201812       35.78,    San Francisco  California\n 0         200012       21.59\n 1         200112       26.15\n 2         200212       19.54\n 3         200312       18.70\n 4         200412       19.32\n 5         200512       27.00\n 6         200612       20.62\n 7         200712       11.68\n 8         200812       14.64\n 9         200912       16.62\n 10        201012       24.17\n 11        201112       16.61\n 12        201212       21.46\n 13        201312        3.39\n 14        201412       20.70\n 15        201512        8.45\n 16        201612       21.40\n 17        201712       25.25\n 18        201812       15.71,    Portland  Oregon\n 0    200012   30.24\n 1    200112   30.47\n 2    200212   31.27\n 3    200312   37.54\n 4    200412   27.69\n 5    200512   36.15\n 6    200612   43.04\n 7    200712   32.10\n 8    200812   27.14\n 9    200912   30.56\n 10   201012   46.24\n 11   201112   37.12\n 12   201212   50.44\n 13   201312   26.75\n 14   201412   40.14\n 15   201512   40.42\n 16   201612   43.38\n 17   201712   45.84\n 18   201812   27.32]"
                    }, 
                    "execution_count": 40
                }
            ], 
            "execution_count": 40
        }, 
        {
            "source": "#### Create a dataframe of precipitation data for each city", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "hou_prec_df = createCityTempDF(precipitation_master_list, 0)\naus_prec_df = createCityTempDF(precipitation_master_list, 1)\nden_prec_df = createCityTempDF(precipitation_master_list, 2)\nsea_prec_df = createCityTempDF(precipitation_master_list, 3)\nsan_prec_df = createCityTempDF(precipitation_master_list, 4)\npor_prec_df = createCityTempDF(precipitation_master_list, 5)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 41
        }, 
        {
            "source": "### Plot Precipation Data for Each City", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# Store precipitation data in variables in preparation for the plot.\n\nx = list(range(0,19))\nx_rev = x[::-1]\n\n# Houston Prec Data 2000 - 2019\ny1 = list(hou_prec_df['Precipitation'])\ny1_lower = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\ny1_lower = y1_lower[::-1]\ntrace1 = go.Scatter(\n    x=x,\n    y=y1,\n    line=dict(color='rgb(81,73,124)'),\n    mode='lines',\n    name='Inches',\n    showlegend=False,\n\n)\n'''trace7 = go.Scatter(\n    x=x+x_rev,\n    y= y1,\n    fill='tozerox',\n    fillcolor='rgba(81,73,124,0.2)',\n    line=dict(color='rgba(255,255,255,0)'),\n    showlegend=False,\n)'''\ny2 = list(aus_prec_df['Precipitation'])\ntrace2 = go.Scatter(\n    x=x,\n    y=y2,\n    line=dict(color='rgb(124,73,116)'),\n    mode='lines',\n    name='Inches',\n    showlegend=False\n)\ny3 = list(den_prec_df['Precipitation'])\ntrace3 = go.Scatter(\n    x=x,\n    y=y3,\n    line=dict(color='rgb(139,115,95)'),\n    mode='lines',\n    name='Inches',\n    showlegend=False\n)\ny4 = list(sea_prec_df['Precipitation'])\ntrace4 = go.Scatter(\n    x=x,\n    y=y4,\n    line=dict(color='rgb(95,119,139)'),\n    mode='lines',\n    name='Inches',\n    showlegend=False\n)\ny5 = list(san_prec_df['Precipitation'])\ntrace5 = go.Scatter(\n    x=x,\n    y=y5,\n    line=dict(color='rgb(110, 115, 119)'),\n    mode='lines',\n    name='Inches',\n    showlegend=False\n)\ny6 = list(san_prec_df['Precipitation'])\ntrace6 = go.Scatter(\n    x=x,\n    y=y6,\n    line=dict(color='rgb(95,119,139)'),\n    mode='lines',\n    name='Inches',\n    showlegend=False\n)\ndata = [trace1, trace2, trace3, trace4, trace5, trace6] #trace7]\n\nfig = tools.make_subplots(rows=3, cols=2, subplot_titles=('Houston', 'Austin',\n                                                          'Denver', 'Seattle',\n                                                          'San Francisco','Portland'))\nfig.append_trace(trace1, 1, 1)\nfig.append_trace(trace2, 1, 2)\nfig.append_trace(trace3, 2, 1)\nfig.append_trace(trace4, 2, 2)\nfig.append_trace(trace5, 3, 1)\nfig.append_trace(trace6, 3, 2)\n\nfig['layout'].update(title='Total Precipitation in U.S. Cities (2000-2018)')\n\npy.iplot(fig)\n", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "This is the format of your plot grid:\n[ (1,1) x1,y1 ]  [ (1,2) x2,y2 ]\n[ (2,1) x3,y3 ]  [ (2,2) x4,y4 ]\n[ (3,1) x5,y5 ]  [ (3,2) x6,y6 ]\n\n"
                }, 
                {
                    "output_type": "execute_result", 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "<plotly.tools.PlotlyDisplay object>", 
                        "text/html": "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~tinaprisma/55.embed\" height=\"525px\" width=\"100%\"></iframe>"
                    }, 
                    "execution_count": 42
                }
            ], 
            "execution_count": 42
        }, 
        {
            "source": "### 11. Cost of Living Considerations\n\nWe researched effective tax rates for each city using:\nhttps://smartasset.com/taxes/oregon-tax-calculator#D3qPPxj0kR\n\nWe researched comparative cost of living (normalized to $100) for each city using:\nhttps://www.nerdwallet.com/cost-of-living-calculator/compare/houston-tx-vs-seattle-wa", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### 12. Salary Differentials Considerations\nDifferent regions of the country provide different salaries: https://datasciencedegree.wisconsin.edu/data-science/data-scientist-salary/\nhttps://learning.oreilly.com/library/view/2016-data-science/9781492049029/ch03.html#idm140536273113840", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# Houston, Austin, Denver, Seattle, San F., Portland\nmean_data_science_salary = [90,90,80,105,125,105]", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 43
        }, 
        {
            "source": "## Create a Model to Predict Whether I'd like a City or Not", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Next, the data will be modeled using a Logistic Regression Algorithm.\n\nThe goal is to classify cities I haven't visited based on my previous experiences.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "'''Note: at first I did this analysis with 6 samples or cities. \nAccording to some smart people-- Long (1997)-- the minimum number of samples is guided by the formula\n\nN = 10k/p,\n\nwhere N is the number of samples, \nk is the number of independent variables, \nand p is the smallest proportion of positive / negative cases.\n\nN = 10*6/.5 = 120 samples... wow... OK! UHM. \n\nIt was really difficult to get all that data for those cities. Maybe I need to decrease my independent variables.\n\nN = 10*3/.5 = 60 samples -- still a lot\n\nOk I need a break.\n\nOk came back from a long break. This realization came too late and I am going to have to incorporate a more thorough analysis in the future.'''", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "'Note: at first I did this analysis with 6 samples or cities. \\nAccording to some smart people-- Long (1997)-- the minimum number of samples is guided by the formula\\n\\nN = 10k/p,\\n\\nwhere N is the number of samples, \\nk is the number of independent variables, \\nand p is the smallest proportion of positive / negative cases.\\n\\nN = 10*6/.5 = 120 samples... wow... OK! UHM. \\n\\nIt was really difficult to get all that data for those cities. Maybe I need to decrease my independent variables.\\n\\nN = 10*3/.5 = 60 samples -- still a lot\\n\\nOk I need a break'"
                    }, 
                    "execution_count": 44
                }
            ], 
            "execution_count": 44
        }, 
        {
            "source": "Let's do some data preparation steps:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# Create a list of the average summer temperatures for each city between 2000-2018\navg_summer_t = [pd.to_numeric(hou_temp_df['Aug Average']).mean(),pd.to_numeric(aus_temp_df['Aug Average']).mean(),\n                pd.to_numeric(den_temp_df['Aug Average']).mean(),pd.to_numeric(sea_temp_df['Aug Average']).mean(),\n                pd.to_numeric(san_temp_df['Aug Average']).mean(),pd.to_numeric(por_temp_df['Aug Average']).mean()]", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 45
        }, 
        {
            "source": "# Create a list of the average winter temperatures for each city between 2000-2018\navg_winter_t = [pd.to_numeric(hou_temp_df['Feb Average']).mean(),pd.to_numeric(aus_temp_df['Feb Average']).mean(),\n                pd.to_numeric(den_temp_df['Feb Average']).mean(),pd.to_numeric(sea_temp_df['Feb Average']).mean(),\n                pd.to_numeric(san_temp_df['Feb Average']).mean(),pd.to_numeric(por_temp_df['Feb Average']).mean()]", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 46
        }, 
        {
            "source": "# Create a list of the average annual precipitation for each city between 2000-2018\navg_prec = [pd.to_numeric(hou_prec_df['Precipitation']).mean(),pd.to_numeric(aus_prec_df['Precipitation']).mean(),\n            pd.to_numeric(den_prec_df['Precipitation']).mean(),pd.to_numeric(sea_prec_df['Precipitation']).mean(),\n            pd.to_numeric(san_prec_df['Precipitation']).mean(),pd.to_numeric(por_prec_df['Precipitation']).mean()]", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 47
        }, 
        {
            "source": "# create a dataframe with all features to be used in the classification exercise. This is the original model I created. It had many features and \n# only a few samples. I learned that I needed to include way more samples if I wanted to use this many features.\n\n'''class_df = pd.DataFrame()\nclass_df['City'] = cities\nclass_df['Outdoors'] = outdoors_count_list\nclass_df['Cultural'] = cultural_count_list\nclass_df['Healthy Foods'] = food_count_list\nclass_df['Avg Summer T.'] = avg_summer_t\nclass_df['Avg Winter T.'] = avg_winter_t\nclass_df['Avg Annual Precip.'] = avg_prec\nclass_df['Tax Rates'] = [.34, .34, .35, .32, .38, .37]\nclass_df['Cost of Living'] = [100,105,120,162,201,136]\nclass_df['Mean Salary'] = mean_data_science_salary\nclass_df['Like?'] = [0,1,0,0,1,1]\nclass_df = class_df.round(2)'''\n", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "# Instead, I chose these three features from the Foursquare Data to run a classification model.\n# The results were not great, since these did not seem to predict preference well.\n# Predicting preferences is very tricky since they are often based on subjective biases and opinions.\n\nclass_df = pd.DataFrame()\nclass_df['City'] = cities\nclass_df['Outdoors'] = outdoors_count_list\nclass_df['Cultural'] = cultural_count_list\nclass_df['Healthy Foods'] = food_count_list\nclass_df['Like?'] = [0,0,0,0,0,0,0,0,0,0,1,0,0,1,1,1,0,0,0,1,0,0,0,0,1,0,1,0,1,0,0,1,1,0,1,0,1,1,1,0,1]\nclass_df = class_df.round(2)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 48
        }, 
        {
            "source": "class_df['Like?'] = class_df['Like?'].astype(int)\nclass_df", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "                    City  Outdoors  Cultural  Healthy Foods  Like?\n0          Anchorage, AK       108         9             32      0\n1     Grand Junction, CO       130        30             39      0\n2            Phoenix, AR       125        10             64      0\n3        Bakersfield, CA       149        28             87      0\n4        Albuquerque, NM       149        13             98      0\n5               Reno, NV       199        14             59      0\n6      Oklahoma City, OK        69        17            122      0\n7             Fresno, CA       154        26            109      0\n8         Des Moines, IA       131        14             82      0\n9        New Orleans, LA       128        19            166      0\n10         St. Louis, MO       175        52            177      1\n11       San Antonio, TX       144        90            214      0\n12         Las Vegas, NV       197        17            219      0\n13           Portland,OR       216       122            322      1\n14     Santa Barbara, CA       218       119            263      1\n15           Houston, TX       180        57            304      1\n16  Colorado Springs, CO       229        49            283      0\n17           Detroit, MI       216        60            334      0\n18            Austin, TX       188       107            297      0\n19     Fort Worth, Texas       209        60            352      1\n20             Miami, FL       228        66            353      0\n21            Dallas, TX       211        59            358      0\n22           Orlando, FL       247        47            348      0\n23             Tampa, FL       265        40            374      0\n24         San Diego, CA       265       118            347      1\n25           Atlanta, GA       284        78            359      0\n26        Sacramento, CA       271       133            396      1\n27            Denver, CO       319        66            359      0\n28           Seattle, WA       349       128            372      1\n29            Boston, MA       415       120            386      0\n30         Arlington, VA       366       165            399      0\n31           Chicago, IL       368       115            408      1\n32        Santa Rosa, CA       390       176            433      1\n33        Long Beach, CA       408       192            468      0\n34       Los Angeles, CA       412       190            464      1\n35          Palmdale, CA       411       188            457      0\n36     San Francisco, CA       487       199            474      1\n37          San Jose, CA       488       202            472      1\n38         Palo Alto, CA       496       202            479      1\n39         New Haven, CT       456       229            480      0\n40          New York, NY       529       257            498      1", 
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>City</th>\n      <th>Outdoors</th>\n      <th>Cultural</th>\n      <th>Healthy Foods</th>\n      <th>Like?</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Anchorage, AK</td>\n      <td>108</td>\n      <td>9</td>\n      <td>32</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Grand Junction, CO</td>\n      <td>130</td>\n      <td>30</td>\n      <td>39</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Phoenix, AR</td>\n      <td>125</td>\n      <td>10</td>\n      <td>64</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Bakersfield, CA</td>\n      <td>149</td>\n      <td>28</td>\n      <td>87</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Albuquerque, NM</td>\n      <td>149</td>\n      <td>13</td>\n      <td>98</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Reno, NV</td>\n      <td>199</td>\n      <td>14</td>\n      <td>59</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Oklahoma City, OK</td>\n      <td>69</td>\n      <td>17</td>\n      <td>122</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Fresno, CA</td>\n      <td>154</td>\n      <td>26</td>\n      <td>109</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Des Moines, IA</td>\n      <td>131</td>\n      <td>14</td>\n      <td>82</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>New Orleans, LA</td>\n      <td>128</td>\n      <td>19</td>\n      <td>166</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>St. Louis, MO</td>\n      <td>175</td>\n      <td>52</td>\n      <td>177</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>San Antonio, TX</td>\n      <td>144</td>\n      <td>90</td>\n      <td>214</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Las Vegas, NV</td>\n      <td>197</td>\n      <td>17</td>\n      <td>219</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Portland,OR</td>\n      <td>216</td>\n      <td>122</td>\n      <td>322</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Santa Barbara, CA</td>\n      <td>218</td>\n      <td>119</td>\n      <td>263</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Houston, TX</td>\n      <td>180</td>\n      <td>57</td>\n      <td>304</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Colorado Springs, CO</td>\n      <td>229</td>\n      <td>49</td>\n      <td>283</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Detroit, MI</td>\n      <td>216</td>\n      <td>60</td>\n      <td>334</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Austin, TX</td>\n      <td>188</td>\n      <td>107</td>\n      <td>297</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Fort Worth, Texas</td>\n      <td>209</td>\n      <td>60</td>\n      <td>352</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Miami, FL</td>\n      <td>228</td>\n      <td>66</td>\n      <td>353</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Dallas, TX</td>\n      <td>211</td>\n      <td>59</td>\n      <td>358</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Orlando, FL</td>\n      <td>247</td>\n      <td>47</td>\n      <td>348</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Tampa, FL</td>\n      <td>265</td>\n      <td>40</td>\n      <td>374</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>San Diego, CA</td>\n      <td>265</td>\n      <td>118</td>\n      <td>347</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>Atlanta, GA</td>\n      <td>284</td>\n      <td>78</td>\n      <td>359</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>Sacramento, CA</td>\n      <td>271</td>\n      <td>133</td>\n      <td>396</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>Denver, CO</td>\n      <td>319</td>\n      <td>66</td>\n      <td>359</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>Seattle, WA</td>\n      <td>349</td>\n      <td>128</td>\n      <td>372</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>Boston, MA</td>\n      <td>415</td>\n      <td>120</td>\n      <td>386</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>Arlington, VA</td>\n      <td>366</td>\n      <td>165</td>\n      <td>399</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>Chicago, IL</td>\n      <td>368</td>\n      <td>115</td>\n      <td>408</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>Santa Rosa, CA</td>\n      <td>390</td>\n      <td>176</td>\n      <td>433</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>Long Beach, CA</td>\n      <td>408</td>\n      <td>192</td>\n      <td>468</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>Los Angeles, CA</td>\n      <td>412</td>\n      <td>190</td>\n      <td>464</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>Palmdale, CA</td>\n      <td>411</td>\n      <td>188</td>\n      <td>457</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>San Francisco, CA</td>\n      <td>487</td>\n      <td>199</td>\n      <td>474</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>San Jose, CA</td>\n      <td>488</td>\n      <td>202</td>\n      <td>472</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>Palo Alto, CA</td>\n      <td>496</td>\n      <td>202</td>\n      <td>479</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>New Haven, CT</td>\n      <td>456</td>\n      <td>229</td>\n      <td>480</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>New York, NY</td>\n      <td>529</td>\n      <td>257</td>\n      <td>498</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    }, 
                    "execution_count": 70
                }
            ], 
            "execution_count": 70
        }, 
        {
            "source": "# Define X and y for this dataset\nX = np.asarray(class_df[['Outdoors','Cultural']])\nX", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "array([[108,   9],\n       [130,  30],\n       [125,  10],\n       [149,  28],\n       [149,  13],\n       [199,  14],\n       [ 69,  17],\n       [154,  26],\n       [131,  14],\n       [128,  19],\n       [175,  52],\n       [144,  90],\n       [197,  17],\n       [216, 122],\n       [218, 119],\n       [180,  57],\n       [229,  49],\n       [216,  60],\n       [188, 107],\n       [209,  60],\n       [228,  66],\n       [211,  59],\n       [247,  47],\n       [265,  40],\n       [265, 118],\n       [284,  78],\n       [271, 133],\n       [319,  66],\n       [349, 128],\n       [415, 120],\n       [366, 165],\n       [368, 115],\n       [390, 176],\n       [408, 192],\n       [412, 190],\n       [411, 188],\n       [487, 199],\n       [488, 202],\n       [496, 202],\n       [456, 229],\n       [529, 257]])"
                    }, 
                    "execution_count": 50
                }
            ], 
            "execution_count": 50
        }, 
        {
            "source": "y = np.asarray(class_df['Like?'])\ny", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n       0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1])"
                    }, 
                    "execution_count": 51
                }
            ], 
            "execution_count": 51
        }, 
        {
            "source": "from sklearn import preprocessing\nX = preprocessing.StandardScaler().fit(X).transform(X)\nX", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "/opt/conda/envs/DSX-Python35/lib/python3.5/site-packages/sklearn/utils/validation.py:475: DataConversionWarning:\n\nData with input dtype int64 was converted to float64 by StandardScaler.\n\n"
                }, 
                {
                    "output_type": "execute_result", 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "array([[-1.29032295, -1.21399141],\n       [-1.1126598 , -0.91653933],\n       [-1.15303779, -1.19982703],\n       [-0.95922344, -0.9448681 ],\n       [-0.95922344, -1.15733387],\n       [-0.55544355, -1.14316949],\n       [-1.60527127, -1.10067633],\n       [-0.91884545, -0.97319687],\n       [-1.1045842 , -1.14316949],\n       [-1.128811  , -1.07234756],\n       [-0.7492579 , -0.60492287],\n       [-0.99960143, -0.06667625],\n       [-0.57159475, -1.10067633],\n       [-0.41815839,  0.38658406],\n       [-0.4020072 ,  0.34409091],\n       [-0.70887991, -0.53410094],\n       [-0.31317562, -0.64741602],\n       [-0.41815839, -0.49160779],\n       [-0.64427513,  0.17411829],\n       [-0.47468758, -0.49160779],\n       [-0.32125122, -0.40662148],\n       [-0.45853638, -0.50577218],\n       [-0.16781486, -0.67574479],\n       [-0.0224541 , -0.77489548],\n       [-0.0224541 ,  0.32992652],\n       [ 0.13098226, -0.23664887],\n       [ 0.02599949,  0.54239229],\n       [ 0.41362818, -0.40662148],\n       [ 0.65589611,  0.47157037],\n       [ 1.18888557,  0.35825529],\n       [ 0.79318127,  0.9956526 ],\n       [ 0.80933247,  0.28743337],\n       [ 0.98699562,  1.15146083],\n       [ 1.13235638,  1.37809099],\n       [ 1.16465877,  1.34976222],\n       [ 1.15658317,  1.32143345],\n       [ 1.77032861,  1.47724168],\n       [ 1.7784042 ,  1.51973484],\n       [ 1.84300899,  1.51973484],\n       [ 1.51998507,  1.90217322],\n       [ 2.10950371,  2.29877599]])"
                    }, 
                    "execution_count": 52
                }
            ], 
            "execution_count": 52
        }, 
        {
            "source": "### Create Train and Test Dataset", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 4)\nprint ('Train set:', X_train.shape, y_train.shape)\nprint ('Test set:', X_test.shape, y_test.shape)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Train set: (32, 2) (32,)\nTest set: (9, 2) (9,)\n"
                }
            ], 
            "execution_count": 53
        }, 
        {
            "source": "### Modeling (Logistic Regression with Scikit-learn)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nLR = LogisticRegression(C=0.01, solver='liblinear').fit(X_train,y_train)\nLR", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n          verbose=0, warm_start=False)"
                    }, 
                    "execution_count": 54
                }
            ], 
            "execution_count": 54
        }, 
        {
            "source": "### Predict Using Test Set", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "yhat = LR.predict(X_test)\nyhat", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "array([1, 1, 0, 0, 1, 0, 0, 0, 0])"
                    }, 
                    "execution_count": 55
                }
            ], 
            "execution_count": 55
        }, 
        {
            "source": "yhat_prob = LR.predict_proba(X_test)\nyhat_prob", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "array([[ 0.46998558,  0.53001442],\n       [ 0.43809005,  0.56190995],\n       [ 0.54708848,  0.45291152],\n       [ 0.53180984,  0.46819016],\n       [ 0.49321011,  0.50678989],\n       [ 0.52765042,  0.47234958],\n       [ 0.5282661 ,  0.4717339 ],\n       [ 0.54306226,  0.45693774],\n       [ 0.51753892,  0.48246108]])"
                    }, 
                    "execution_count": 56
                }
            ], 
            "execution_count": 56
        }, 
        {
            "source": "## Results\n### Evaluation of Model", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# Compute Jaccard Index\n\nfrom sklearn.metrics import jaccard_similarity_score\njaccard_similarity_score(y_test, yhat)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "0.66666666666666663"
                    }, 
                    "execution_count": 57
                }
            ], 
            "execution_count": 57
        }, 
        {
            "source": "# Confusion Matrix\n\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\nprint(confusion_matrix(y_test, yhat, labels=[1,0]))", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "[[2 2]\n [1 4]]\n"
                }
            ], 
            "execution_count": 58
        }, 
        {
            "source": "# Compute confusion matrix\ncnf_matrix = confusion_matrix(y_test, yhat, labels=[1,0])\nnp.set_printoptions(precision=2)\n\n\n# Plot non-normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=['like=1','like=0'],normalize= False,  title='Confusion matrix')", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Confusion matrix, without normalization\n[[2 2]\n [1 4]]\n"
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "image/png": "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\n", 
                        "text/plain": "<matplotlib.figure.Figure at 0x7f9e6bce70b8>"
                    }, 
                    "metadata": {}
                }
            ], 
            "execution_count": 59
        }, 
        {
            "source": "print(classification_report(y_test, yhat))", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "             precision    recall  f1-score   support\n\n          0       0.67      0.80      0.73         5\n          1       0.67      0.50      0.57         4\n\navg / total       0.67      0.67      0.66         9\n\n"
                }
            ], 
            "execution_count": 60
        }, 
        {
            "source": "from sklearn.metrics import log_loss\nlog_loss(y_test, yhat_prob)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "0.67006045766557787"
                    }, 
                    "execution_count": 61
                }
            ], 
            "execution_count": 61
        }, 
        {
            "source": "## Discussion", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "This log loss value is pretty high. Our model is not doing a good job of classifying which cities we would prefer.\n\nIn order to improve this model, we would have to extract data from many other cities.\n\nWe should consider other more prescriptive parameters. However, it's very time consuming to get data for all these cities and the time\n\npressure of the deadline approached. In the near future, we will improve on this model and republish the results in my personal blog.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "###  Future Work: Other Datasets to Consider\n####  Pollen and Mold Data", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Pollen Data Source - Web Scraping Exercise (Complicated)\n\nHOUSTON DATA - Station 188\nhttp://pollen.aaaai.org/nab/index.cfm?p=AllergenCalendar&stationid=188&qsFullDate=10/1/2018\n\nAUSTIN DATA - Station 111 \n\nDENVER DATA - Station 196\n\nSAN JOSE DATA - Station 108\n\nSEATTLE DATA - Station 3\n\nPORTLAND DATA - Station 1\n\n\nMold Spore Count Houston\nhttp://www.houstontx.gov/health/Pollen-Mold/mold-archives.html\n\nWhat the Numbers Mean\nhttp://www.houstontx.gov/health/Pollen-Mold/numbers.html\n\n\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "from PIL import Image\nimport requests\nfrom io import BytesIO\nurl = 'https://www.zyrtec.com/sites/zyrtec_us/files/field/image/pollen-types-by-month-guide.jpg'\nresponse = requests.get(url)\nimg = Image.open(BytesIO(response.content))\nimg", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "###          Other Sources and Statistics to Consider:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "I will have to think more deeply about where to find reliable data regarding these statistics and how to integrate them into my analysis: Healthiest US Cities, Best standard of living, cost of living, demographics.\n\nThis website contains open government data.\nhttps://cities.data.gov/", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## Conclusion", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "We had some success with a limited dataset to predict preferences.\nPredicting preferences is extremely difficult since there are so many variables and many are subjective.\nI thought this exercise would come up with a more clear-cut result!\n\nExtending this example to other applications, marketers love to segment populations based on preferences, but this is a very complicated \nexercise. No wonder the tech companies want all the data they can gather about us.\n\nIt takes 10*(# of independent variables)/(smallest portion of yes/no preference) samples to be able to start having some success with\nclassification algorithms.\n\nTo improve this exercise, many more samples need to be taken. Therefore, I need to get a job so I am able to start travelling to all\nthese cities!", 
            "cell_type": "markdown", 
            "metadata": {}
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.5", 
            "name": "python", 
            "pygments_lexer": "ipython3", 
            "file_extension": ".py", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}
